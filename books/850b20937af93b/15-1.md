---
title: "15.1 Haskellでの米田"
---


We have already encountered the hom-functor in Haskell under the guise
of the reader functor:

\src{snippet01}
The reader maps morphisms (here, functions) by precomposition:

\src{snippet02}
The Yoneda lemma tells us that the reader functor can be naturally
mapped to any other functor.

A natural transformation is a polymorphic function. So given a functor
\code{F}, we have a mapping to it from the reader functor:

\src{snippet03}
As usual, \code{forall} is optional, but I like to write it explicitly
to emphasize parametric polymorphism of natural transformations.

The Yoneda lemma tells us that these natural transformations are in
one-to-one correspondence with the elements of \code{F a}:

\begin{snipv}
forall x . (a -> x) -> F x \ensuremath{\cong} F a
\end{snipv}
The right hand side of this identity is what we would normally consider
a data structure. Remember the interpretation of functors as generalized
containers? \code{F a} is a container of \code{a}. But the left
hand side is a polymorphic function that takes a function as an
argument. The Yoneda lemma tells us that the two representations are
equivalent --- they contain the same information.

Another way of saying this is: Give me a polymorphic function of the
type:

\src{snippet04}
and I'll produce a container of \code{a}. The trick is the one we used
in the proof of the Yoneda lemma: we call this function with \code{id}
to get an element of \code{F a}:

\src{snippet05}
The converse is also true: Given a value of the type \code{F a}:

\src{snippet06}
one can define a polymorphic function:

\src{snippet07}
of the correct type. You can easily go back and forth between the two
representations.

The advantage of having multiple representations is that one might be
easier to compose than the other, or that one might be more efficient in
some applications than the other.

The simplest illustration of this principle is the code transformation
that is often used in compiler construction: the continuation passing
style or \acronym{CPS}. It's the simplest application of the Yoneda lemma to the
identity functor. Replacing \code{F} with identity produces:

\begin{snipv}
forall r . (a -> r) -> r \ensuremath{\cong} a
\end{snipv}
The interpretation of this formula is that any type \code{a} can be
replaced by a function that takes a ``handler'' for \code{a}. A
handler is a function accepting \code{a} and performing the rest of
the computation --- the continuation. (The type \code{r} usually
encapsulates some kind of status code.)

This style of programming is very common in UIs, in asynchronous
systems, and in concurrent programming. The drawback of \acronym{CPS} is that it
involves inversion of control. The code is split between producers and
consumers (handlers), and is not easily composable. Anybody who's done
any amount of nontrivial web programming is familiar with the nightmare
of spaghetti code from interacting stateful handlers. As we'll see
later, judicious use of functors and monads can restore some
compositional properties of \acronym{CPS}.


（和訳：[@ashiato45](https://twitter.com/ashiato45)）
